# Cursor Learning Overlay

Transform your coding breaks into productive microlearning opportunities. This extension provides a manual fun fact button that opens a fullscreen learning overlay with engaging educational content and quizzes.

## Features

- **Manual Fun Fact Button**: Click the ðŸŽ“ Fun Fact button in the status bar to open the overlay
- **Personalized Topics**: Choose your interests during setup (like Twitter onboarding)
- **Dynamic Content Generation**: Fresh fun facts and quizzes generated by LLM every 30 seconds
- **Seamless Integration**: Shows inside Cursor IDE - blocks the entire interface
- **Local LLM Integration**: Uses Ollama for content generation (no external API keys needed)
- **Keyboard Shortcut**: Use `Cmd+Alt+F` (Mac) or `Ctrl+Alt+F` (Windows/Linux) to quickly open
- **Configurable**: Toggle button visibility in settings

## Prerequisites

1. **Ollama**: Install and run Ollama locally
   ```bash
   # Install Ollama (macOS)
   brew install ollama
   
   # Start Ollama
   ollama serve
   
   # Pull a model (recommended: wizardlm2:latest)
   ollama pull wizardlm2:latest
   ```

2. **Cursor IDE**: This extension is specifically designed for Cursor IDE

## Installation

1. Clone this repository
2. Install dependencies:
   ```bash
   npm install
   ```
3. Compile the extension:
   ```bash
   npm run compile
   ```
4. Press `F5` in VS Code to run the extension in a new Extension Development Host window

## Usage

### How It Works

1. **First-Time Setup**: Choose your learning topics during initial setup
2. **Agent Detection**: Monitors for Cursor's AI agent activity
3. **Smart Overlay**: Only appears when agent is actually working (not just idle)
4. **Dynamic Content**: Generates fresh fun facts and quizzes every 30 seconds
5. **Seamless Experience**: Blocks Cursor IDE completely during agent work
6. **Auto-Hide**: Disappears when agent finishes, so you can interact with results

### Manual Controls (Optional)

- **Toggle Overlay**: `Ctrl+Shift+P` â†’ "Learning: Toggle Learning Overlay"
- **Test Mode**: `Ctrl+Shift+P` â†’ "Learning: Simulate Agent (Test)" to manually trigger

### Configuration

Open Settings (`Ctrl+,`) and search for "Cursor Learning Overlay" to configure:

- **Topics**: Choose your learning topics (JavaScript, TypeScript, React, etc.)
- **Ollama URL**: Default is `http://localhost:11434`
- **Model**: Default is `wizardlm2:latest`
- **Enabled**: Toggle the extension on/off

### Learning Flow

1. **Fun Fact**: See an interesting fact about your chosen topic
2. **Test Me**: Click to reveal a multiple choice question
3. **Answer**: Select your answer
4. **Explanation**: See the correct answer and explanation
5. **Next**: Continue with more questions or close the overlay

## How It Works

1. **Agent Detection**: Monitors for AI agent activity (currently simulated with idle detection)
2. **Content Generation**: Uses Ollama to generate personalized learning content
3. **Smart Caching**: Avoids repeating questions and tracks your learning history
4. **Seamless Integration**: Overlay appears/disappears automatically

## Development

### Project Structure

```
src/
â”œâ”€â”€ extension.ts              # Main extension entry point
â”œâ”€â”€ learningOverlayManager.ts # Manages the fullscreen overlay
â”œâ”€â”€ ollamaService.ts          # Handles Ollama API integration
â””â”€â”€ localStorage.ts           # Manages user preferences and history
```

### Building

```bash
# Compile TypeScript
npm run compile

# Watch for changes
npm run watch
```

### Testing

1. Run the extension in development mode (`F5`)
2. Use the "Simulate Agent (Test)" command to test the overlay
3. Check the console for debug information

## Future Enhancements

- **Real Agent Integration**: Connect to actual Cursor AI agent events
- **Cloud Sync**: Sync learning progress across devices
- **Gamification**: Add streaks, XP, and achievements
- **More Content Types**: Code snippets, coding challenges, etc.
- **Analytics**: Track learning progress and topic mastery

## Troubleshooting

### Ollama Not Running
- Make sure Ollama is installed and running: `ollama serve`
- Check the Ollama URL in settings (default: `http://localhost:11434`)
- Verify the model is available: `ollama list`

### Overlay Not Appearing
- Check if the extension is enabled in settings
- Try the manual toggle command
- Check the console for error messages

### Content Not Generating
- Verify Ollama is running and accessible
- Check your internet connection (for model downloads)
- Try a different model in settings

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## License

MIT License - see LICENSE file for details
